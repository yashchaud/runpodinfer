# vLLM and inference dependencies
vllm>=0.6.1
torch>=2.1.0
transformers>=4.40.0

# FastAPI and server dependencies
fastapi>=0.110.0
uvicorn[standard]>=0.27.0
httpx>=0.27.0

# HuggingFace utilities
huggingface-hub>=0.20.0

# Multimodal support
pillow>=10.0.0
